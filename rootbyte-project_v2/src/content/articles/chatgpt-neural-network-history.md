---
title: "ChatGPT Is 3 Years Old. The Math Behind It Is 83."
date: 2026-02-22
category: ai
tags: [ai, chatgpt, openai, neural-networks, history, machine-learning]
root_year: 1943
root_who: "Warren McCulloch & Walter Pitts"
root_where: "University of Illinois / MIT"
root_connection: "Their 17-page paper on mathematical neurons is the direct ancestor of every AI running today"
dyk_fact: "The word 'Artificial Intelligence' was coined at a 1956 Dartmouth workshop with a budget of $7,500 — the same question is now a multi-trillion dollar industry"
future_headline: "From Assistant to Agent — The Road to AGI"
future_prediction: "By 2028, AI systems will autonomously plan and execute multi-day projects with minimal human checkpoints. By 2035, the debate shifts from 'can it think' to 'should it decide'."
future_year: "2028–2035"
future_stage: "in active development"
tomorrow_teaser: true
hero_image: /images/articles/chatgpt-neural-history.webp
reading_time: 8
status: published
---

## The Modern Story

On November 30, 2022, OpenAI launched ChatGPT. In five days, it had a million users. In two months, 100 million — the fastest consumer product adoption in history. By 2026, it's used by hundreds of millions of people daily for writing, coding, research, and conversation.

Everyone talks about what ChatGPT does today. Almost nobody talks about the 83-year chain of human thought that had to happen first.

## ROOT: Going Back to 1943

Warren McCulloch was a neurologist. Walter Pitts was a 15-year-old runaway living under a bridge in Chicago, who had read Bertrand Russell's *Principia Mathematica* and memorized it. McCulloch found him. Together, they wrote a 17-page paper.

Published in 1943, *"A Logical Calculus of the Ideas Immanent in Nervous Activity"* described a mathematical model of how neurons fire. The model was simple: inputs come in, if they cross a threshold, the neuron fires an output. They showed mathematically that a network of these could compute *anything*.

No computer could run it. They had no hardware. The paper sat largely ignored for a decade.

**The chain that followed:**
- **1956** — John McCarthy coins "Artificial Intelligence" at Dartmouth. Budget: $7,500. Ambition: solve it in a summer.
- **1969** — Minsky and Papert publish *Perceptrons*, arguing neural networks can't solve complex problems. The field collapses. "AI Winter" begins.
- **1986** — Rumelhart, Hinton, and Williams revive the McCulloch-Pitts dream with backpropagation — a way to train networks from data. Nobody cares yet.
- **2012** — AlexNet crushes every competitor on image recognition. Hinton's lab at the University of Toronto proves deep learning works at scale. The modern AI race begins.
- **2017** — Google publishes *"Attention Is All You Need"* — the Transformer architecture that powers GPT.
- **2022** — ChatGPT. 83 years after a neurologist and a homeless teenager published a math paper.

## Did You Know

The 1943 McCulloch-Pitts paper was mathematically proven to be logically complete — meaning a network of their artificial neurons could, in theory, compute anything a modern Turing machine can. They proved the ceiling **before** the technology to reach it existed by 80 years.

## Why It Matters Today

The AI you use daily isn't the product of one company, one decade, or one country. It's the product of:
- A UK mathematician (Turing) building the theory of computation in 1936
- Two American researchers formalizing the mathematical neuron in 1943
- A Canadian-born researcher (Hinton) proving deep learning works in 2012
- An American company (OpenAI) putting a chat interface on top in 2022

Progress in technology doesn't happen in press releases. It happens in papers nobody reads, at conferences nobody attends, funded by grants nobody remembers — until suddenly it's everywhere and everyone acts like it appeared from nowhere.

---

## FUTURE: From Assistant to Agent — The Road to AGI

> ⚠️ This section is speculative — based on active research, roadmaps, and expert analysis. Not yet reality.

McCulloch and Pitts modeled a single neuron in 1943. Today's largest AI models simulate hundreds of billions of parameters approximating neural behavior. The trajectory is clear. The destination is debated.

### The Agentic Shift (2025–2028)
Current AI tools wait for you to ask them something. The next phase — already underway — is **agentic AI**: systems that accept a goal, plan sub-tasks, use tools (browsers, code execution, APIs), self-correct, and run autonomously until done.

OpenAI's `o3`, Google's Gemini Ultra, and Anthropic's Claude are already executing multi-step tasks. By 2027–2028, AI "workers" will be given week-long projects with minimal checkpoints — not chat turns.

**Prediction:** By 2028, at least 3 Fortune 500 companies will have an AI system as a standing member of a product team, assigned to a role with deliverables.

### Artificial General Intelligence — The Honest Timeline
AGI (a system that can match or exceed human performance across all cognitive tasks) is the 1943 paper's ultimate destination. Current expert estimates range from 5 to 50 years, with serious researchers across the full range.

What McCulloch and Pitts couldn't have imagined: when it arrives, the hardest problem won't be building it. It will be deciding what it's allowed to do.

**The root still holds:** Every AI milestone traces back to that 1943 paper written by a neurologist and a teenage runaway who had nowhere to sleep. The next milestone will too.
